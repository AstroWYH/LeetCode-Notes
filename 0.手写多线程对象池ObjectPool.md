```cpp
#include <atomic>
#include <deque>
#include <list>
#include <memory>
#include <mutex>
#include <queue>
#include <string>
#include <thread>
#include <unordered_map>
#include <utility>
#include <vector>

#include "boost/lockfree/queue.hpp"

template <class ObjectType>
class BaseObjectPool {
 public:
  typedef std::shared_ptr<ObjectType> ObjectTypePtr;
  BaseObjectPool() = default;
  virtual ~BaseObjectPool() = default;
  virtual ObjectTypePtr Get() = 0;
  virtual void BatchGet(size_t num, std::vector<ObjectTypePtr>* data) = 0;
  virtual void BatchGet(size_t num, bool is_front,
                        std::list<ObjectTypePtr>* data) = 0;
  virtual void BatchGet(size_t num, bool is_front,
                        std::deque<ObjectTypePtr>* data) = 0;
  virtual void set_capacity(size_t capacity) { (void)capacity; }
  virtual size_t get_capacity() { return capacity_; }
  virtual size_t RemainedNum() { return 0; }

 protected:
  size_t capacity_ = 0;

  DISALLOW_COPY_AND_ASSIGN(BaseObjectPool);
};

template <class ObjectType>
class DummyObjectPool : public BaseObjectPool<ObjectType> {
 public:
  using typename BaseObjectPool<ObjectType>::ObjectTypePtr;
  static DummyObjectPool& Instance() {
    static DummyObjectPool pool;
    return pool;
  }
  ObjectTypePtr Get() override {
    return std::shared_ptr<ObjectType>(new ObjectType);
  }
  void BatchGet(size_t num, std::vector<ObjectTypePtr>* data) override {
    for (size_t i = 0; i < num; ++i) {
      data->emplace_back(ObjectTypePtr(new ObjectType));
    }
  }
  void BatchGet(size_t num, bool is_front,
                std::list<ObjectTypePtr>* data) override {
    for (size_t i = 0; i < num; ++i) {
      is_front ? data->emplace_front(ObjectTypePtr(new ObjectType))
               : data->emplace_back(ObjectTypePtr(new ObjectType));
    }
  }
  void BatchGet(size_t num, bool is_front,
                std::deque<ObjectTypePtr>* data) override {
    for (size_t i = 0; i < num; ++i) {
      is_front ? data->emplace_front(ObjectTypePtr(new ObjectType))
               : data->emplace_back(ObjectTypePtr(new ObjectType));
    }
  }

 protected:
  DummyObjectPool() = default;
};

template <typename T>
class BaseConcurrentQueue {
 public:
  BaseConcurrentQueue() = default;
  virtual ~BaseConcurrentQueue() = default;
  virtual bool IsLockFree() const = 0;
  virtual bool Empty() const = 0;
  virtual bool Push(const T& data) = 0;
  virtual bool PushUnsafe(const T& data) = 0;
  virtual bool Pop(T* data) = 0;
  virtual bool PopUnsafe(T* data) = 0;

 private:
  DISALLOW_COPY_AND_ASSIGN(BaseConcurrentQueue);
};

class SpinLock {
 private:
  std::atomic_flag lck = ATOMIC_FLAG_INIT;

 public:
  void lock() {
    while (lck.test_and_set(std::memory_order_acquire)) {
    }
  }
  void unlock() { lck.clear(std::memory_order_release); }
};

template <typename T>
class StlBlockingQueue : public BaseConcurrentQueue<T> {
 public:
  StlBlockingQueue() = default;
  virtual ~StlBlockingQueue() = default;
  bool IsLockFree() const override { return false; }
  bool Empty() const override {
    std::lock_guard<LockType> lock(mutex_);
    bool empty = queue_.empty();
    return empty;
  }
  bool Push(const T& data) override {
    std::lock_guard<LockType> lock(mutex_);
    queue_.push(data);
    return true;
  }
  bool PushUnsafe(const T& data) override {
    queue_.push(data);
    return true;
  }
  bool Pop(T* data) override {
    std::lock_guard<LockType> lock(mutex_);
    if (queue_.empty()) {
      return false;
    }
    *data = queue_.front();
    queue_.pop();
    return true;
  }
  bool PopUnsafe(T* data) override {
    if (queue_.empty()) {
      return false;
    }
    *data = queue_.front();
    queue_.pop();
    return true;
  }

 protected:
  std::queue<T> queue_;
  // typedef SpinLock LockType;
  typedef std::mutex LockType;
  mutable LockType mutex_;
};

template <typename T>
class BoostLockFreeQueue : public BaseConcurrentQueue<T> {
 public:
  BoostLockFreeQueue() = default;
  virtual ~BoostLockFreeQueue() = default;
  bool IsLockFree() const override { return queue_.is_lock_free(); }
  bool Empty() const override { return queue_.empty(); }
  bool Push(const T& data) override { return queue_.push(data); }
  bool PushUnsafe(const T& data) override {
    return queue_.unsynchronized_push(data);
  }
  bool Pop(T* data) override { return queue_.pop(*data); }
  bool PopUnsafe(T* data) override { return queue_.unsynchronized_pop(*data); }

 protected:
  mutable boost::lockfree::queue<T> queue_;
};

// #define PERCEPTION_BASE_DISABLE_POOL

static const size_t kPoolDefaultExtendNum = 0;
static const size_t kPoolDefaultSize = 100;

template <class T>
struct ObjectPoolDefaultInitializer {
  void operator()(T* t) const { (void)t; }
};

template <class ObjectType, size_t N = kPoolDefaultSize,
          class Initializer = ObjectPoolDefaultInitializer<ObjectType> >
class ConcurrentObjectPool
    : public BaseObjectPool<ObjectType>,
      public std::enable_shared_from_this<
          ConcurrentObjectPool<ObjectType, N, Initializer> > {
 public:
  using typename BaseObjectPool<ObjectType>::ObjectTypePtr;
  using BaseObjectPool<ObjectType>::capacity_;
  static ConcurrentObjectPool& Instance(
      const std::string& pool_name = "default") {
    typedef std::shared_ptr<ConcurrentObjectPool> ConcurrentObjectPoolPtr;
    static std::unordered_map<std::string, ConcurrentObjectPoolPtr> object_pool;
    auto itr = object_pool.find(pool_name);
    if (itr == object_pool.end()) {
      auto ret =
          object_pool.insert(std::pair<std::string, ConcurrentObjectPoolPtr>(
              pool_name,
              ConcurrentObjectPoolPtr(new ConcurrentObjectPool(N, pool_name))));
      return *(ret.first->second);
    }
    return *(itr->second);
  }
  ObjectTypePtr Get() override {
#ifndef PERCEPTION_BASE_DISABLE_POOL
    std::weak_ptr<ConcurrentObjectPool> self = this->shared_from_this();
    ObjectType* ptr = nullptr;
    {
      std::lock_guard<std::mutex> lock(mutex_);
      if (!queue_->Pop(&ptr)) {
        const auto orig_capacity = capacity_;
        Add(1 + kPoolDefaultExtendNum);
        CHECK(queue_->Pop(&ptr));
        LOG_WARN << "[" << pool_name_ << "] Extend pool from " << orig_capacity
                 << " to " << capacity_;
      }
    }
    return ObjectTypePtr(ptr, [self](ObjectType* obj_ptr) {
      if (auto pool = self.lock()) {
        kInitializer(obj_ptr);
        CHECK(pool->queue_->Push(obj_ptr));
      }
    });
#else
    return ObjectTypePtr(new ObjectType);
#endif
  }
  void BatchGet(size_t num, std::vector<ObjectTypePtr>* data) override {
#ifndef PERCEPTION_BASE_DISABLE_POOL
    std::weak_ptr<ConcurrentObjectPool> self = this->shared_from_this();
    std::vector<ObjectType*> buffer(num, nullptr);
    {
      std::lock_guard<std::mutex> lock(mutex_);
      for (size_t i = 0; i < num; ++i) {
        if (!queue_->Pop(&buffer[i])) {
          const auto orig_capacity = capacity_;
          Add(num - i + kPoolDefaultExtendNum);
          CHECK(queue_->Pop(&buffer[i]));
          LOG_WARN << "[" << pool_name_ << "] Extend pool from "
                   << orig_capacity << " to " << capacity_;
        }
      }
    }
    for (size_t i = 0; i < num; ++i) {
      data->emplace_back(ObjectTypePtr(buffer[i], [self](ObjectType* obj_ptr) {
        if (auto pool = self.lock()) {
          kInitializer(obj_ptr);
          CHECK(pool->queue_->Push(obj_ptr));
        }
      }));
    }
#else
    for (size_t i = 0; i < num; ++i) {
      data->emplace_back(ObjectTypePtr(new ObjectType));
    }
#endif
  }
  void BatchGet(size_t num, bool is_front,
                std::list<ObjectTypePtr>* data) override {
#ifndef PERCEPTION_BASE_DISABLE_POOL
    std::weak_ptr<ConcurrentObjectPool> self = this->shared_from_this();
    std::vector<ObjectType*> buffer(num, nullptr);
    {
      std::lock_guard<std::mutex> lock(mutex_);
      for (size_t i = 0; i < num; ++i) {
        if (!queue_->Pop(&buffer[i])) {
          const auto orig_capacity = capacity_;
          Add(num - i + kPoolDefaultExtendNum);
          CHECK(queue_->Pop(&buffer[i]));
          LOG_WARN << "[" << pool_name_ << "] Extend pool from "
                   << orig_capacity << " to " << capacity_;
        }
      }
    }
    for (size_t i = 0; i < num; ++i) {
      is_front ? data->emplace_front(
                     ObjectTypePtr(buffer[i],
                                   [self](ObjectType* obj_ptr) {
                                     if (auto pool = self.lock()) {
                                       kInitializer(obj_ptr);
                                       CHECK(pool->queue_->Push(obj_ptr));
                                     }
                                   }))
               : data->emplace_back(
                     ObjectTypePtr(buffer[i], [self](ObjectType* obj_ptr) {
                       if (auto pool = self.lock()) {
                         kInitializer(obj_ptr);
                         CHECK(pool->queue_->Push(obj_ptr));
                       }
                     }));
    }
#else
    for (size_t i = 0; i < num; ++i) {
      is_front ? data->emplace_front(ObjectTypePtr(new ObjectType))
               : data->emplace_back(ObjectTypePtr(new ObjectType));
    }
#endif
  }
  void BatchGet(size_t num, bool is_front,
                std::deque<ObjectTypePtr>* data) override {
#ifndef PERCEPTION_BASE_DISABLE_POOL
    std::vector<ObjectType*> buffer(num, nullptr);
    {
      std::lock_guard<std::mutex> lock(mutex_);
      for (size_t i = 0; i < num; ++i) {
        if (!queue_->Pop(&buffer[i])) {
          const auto orig_capacity = capacity_;
          Add(num - i + kPoolDefaultExtendNum);
          CHECK(queue_->Pop(&buffer[i]));
          LOG_WARN << "[" << pool_name_ << "] Extend pool from "
                   << orig_capacity << " to " << capacity_;
        }
      }
    }
    for (size_t i = 0; i < num; ++i) {
      is_front
          ? data->emplace_front(ObjectTypePtr(buffer[i],
                                              [&](ObjectType* obj_ptr) {
                                                kInitializer(obj_ptr);
                                                CHECK(queue_->Push(obj_ptr));
                                              }))
          : data->emplace_back(
                ObjectTypePtr(buffer[i], [&](ObjectType* obj_ptr) {
                  kInitializer(obj_ptr);
                  CHECK(queue_->Push(obj_ptr));
                }));
    }
#else
    for (size_t i = 0; i < num; ++i) {
      is_front ? data->emplace_front(ObjectTypePtr(new ObjectType))
               : data->emplace_back(ObjectTypePtr(new ObjectType));
    }
#endif
  }
#ifndef PERCEPTION_BASE_DISABLE_POOL
  void set_capacity(size_t capacity) override {
    if (capacity_ < capacity) {
      std::lock_guard<std::mutex> lock_guard(mutex_);
      Add(capacity - capacity_);
    }
  }
#endif
  size_t get_capacity() override {
    std::lock_guard<std::mutex> lock(mutex_);
    size_t capacity = capacity_;
    return capacity;
  }
  ~ConcurrentObjectPool() override { ReleaseMemory(); }

 protected:
#ifndef PERCEPTION_BASE_DISABLE_POOL
  void Add(size_t num) {
    for (size_t i = 0; i < num; ++i) {
      ObjectType* ptr = new ObjectType;
      kInitializer(ptr);
      extended_cache_.push_back(ptr);
      CHECK(queue_->Push(ptr));
    }
    capacity_ = kDefaultCacheSize + extended_cache_.size();
  }
#endif
  explicit ConcurrentObjectPool(size_t default_size,
                                const std::string& pool_name)
      : kDefaultCacheSize(default_size), pool_name_(pool_name) {
    queue_.reset(new BoostLockFreeQueue<ObjectType*>);
    // queue_.reset(new StlBlockingQueue<ObjectType*>);
    AllocateMemory();
  }
  void AllocateMemory() {
#ifndef PERCEPTION_BASE_DISABLE_POOL
    cache_ = new ObjectType[kDefaultCacheSize];
    for (size_t i = 0; i < kDefaultCacheSize; ++i) {
      kInitializer(&cache_[i]);
      CHECK(queue_->PushUnsafe(&cache_[i]));
    }
    capacity_ = kDefaultCacheSize;
#endif
  }
  void ReleaseMemory() {
    queue_.reset();
    if (cache_) {
      delete[] cache_;
      cache_ = nullptr;
    }
    for (auto& ptr : extended_cache_) {
      delete ptr;
    }
    extended_cache_.clear();
  }
  std::unique_ptr<BaseConcurrentQueue<ObjectType*> > queue_;
  std::mutex mutex_;
  ObjectType* cache_ = nullptr;
  const size_t kDefaultCacheSize;
  std::list<ObjectType*> extended_cache_;
  static inline const Initializer kInitializer;
  std::string pool_name_ = "default";
};

```
